---
bg: "tools.jpg"
layout: post
title:  "	spark协同过滤推荐算法调用"
crawlertitle: "机器学习"
summary: "《spark机器学习》上的推荐系统例子。"
date:   2016-10-16 10:32:19 +0800
categories: posts
tags: ['机器学习']
author: haohhxx
---

《spark机器学习》上的推荐系统例子。跑的是GroupLens_MovieLens数据集中的ml-100k（数据集下载链接[MovieLens 100K Dataset](http://files.grouplens.org/datasets/movielens/ml-100k.zip "MovieLens 100K Dataset")）
分别实现了用户推荐和物品推荐。


`````scala
package test

/**
  * User: hao
  * Date: 2016/10/10 0010
  * Time: 18:59
  */
import org.apache.spark.mllib.recommendation.{ALS, Rating}
import org.apache.spark.{SparkConf, SparkContext}

import scala.io.Source
import org.jblas.DoubleMatrix


object Simple_question {

  def cosineSimilarity(vec1: DoubleMatrix, vec2: DoubleMatrix): Double = {
    vec1.dot(vec2) / (vec1.norm2() * vec2.norm2())
  }



  def main(args: Array[String]) {
    val conf = new SparkConf().setAppName("Simple Application").setMaster("local")
    val sc = new SparkContext(conf)

    val fileroot = "/home/hao/桌面/recommend/GroupLens_MovieLens数据集/ml-100k/u.data"
    val rawData = sc.textFile(fileroot)
    val rawRatings = rawData.map(_.split("\t").take(3))

    val ratings = rawRatings.map{
      case Array(user,movie,rating) => Rating(user.toInt,movie.toInt,rating.toDouble)
    }

    val model = ALS.train(ratings,50,10,0.01)

    val movies = sc.textFile("/home/hao/桌面/recommend/GroupLens_MovieLens数据集/ml-100k/u.item")
    val titles = movies.map(line => line.split("\\|")
      .take(2)).map(array => (array(0).toInt , array(1))).collectAsMap()


    val itemId = 567
    val itemFactor = model.productFeatures.lookup(itemId).head
    val itemVector = new DoubleMatrix(itemFactor)

	val sims = model.productFeatures.map{
      case(id,factor) =>
      val factorVector = new DoubleMatrix(factor)
      val sim = cosineSimilarity(factorVector , itemVector)
      (id, sim)
    }

    val sortedSims = sims.top(10)(
        Ordering.by[(Int,Double), Double]{
        case(id,similarity) => similarity
      })
    println(sortedSims.take(10).mkString("\n"))
  }
}

`````
